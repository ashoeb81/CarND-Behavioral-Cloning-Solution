# Behavioral Cloning Project

## Data

To generate the data used for this project, I drove the car around both tracks for multiple laps (at least 4 laps around both tracks 1 and 2).  The driving involved both centerline driving as well as recovery from weaving out to the right and left edges of the road.  My driving generated a dataset of 9622 frames with their associated steering angles.  The graph below illustrates a histogram of the recorded steering angles.  The histogram shows that the steering angles are between -1 and 1 with a significant fraction of the steering angles equal to 0.  In fact, ~50% of the recorded frames are associated with a steering angle of zero.

![Screenshot](images/data_histogram.png)

The recorded frames (9622 frames) were **shuffled and split** into a training (7698 frames), testing (962 frames), and validation (962) sets.  Furthermore, only frames with non-zero steering angles were used to train, test, and validate the model.  The distribution of the train, test, and validation datasets are shown below.

![Screenshot](images/train_test_validate_histogram.png)

## Model

My convolutional neural network uses an architecture that progressively transforms the input from a representation that is "wide and shallow" (e.g. input is 20 X 20 X 3 which is large in height and width but shallow in depth) to a representation that is "narrow and deep" (e.g. the output of my last convolutional layer is 3 X 3 X 64). Each additional depth dimension is a learned feature map that helps the network solve the classification task. 

Specifically, my architecture contains three successive convolutional layers followed by two successive fully-connected layers. Each convolutional layer employs a ReLU activation function, , and 2X2 max-pooling with a stride of 2 in each dimension. During training, the output of the second fully-connected layer passes through a dropout layer prior to being fed into the model's output layer (the layer that produces the logit scores for the 43 classes).


To go from "wide and shallow" to "narrow and deep", the number of feature maps doubles between each layer of the model as the dimensions are halved (due to the stride of the max pooling layers). So we start with 10X10X16 feature maps at the output of the first convolutional layer, 5X5X32 at the output of the second, 3X3X64 at the output of the third. The number of output nodes generated by the fully-connected layers also follows this pattern. So the output of the first fully-connected layer is 128 while the output of the second is 256. The model's final layer maps these 256 values to 43 logit scores. 

The filters employed by the convolutional layers are also progressively shrunk to accomodate the halving of the spatial dimensions between model layers. So, we start with 7X7 filters in the first convolutional layer, 5X5 in the second convolutional layers, and 3X3 in the third and last convolutional layer. 


![Screenshot](images/model_architecture.png)

